{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oX6K_-JCtiL"
   },
   "source": [
    "**Modulo 3: TensorFlow y Keras para Neural Networks**\n",
    "* Instructor: [Juan Maniglia](https://juanmaniglia.github.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOY9MHVrCtiM"
   },
   "source": [
    "# Parte 3.2: Introducción a Tensorflow y Keras\n",
    "\n",
    "TensorFlow es una biblioteca de software de código abierto para Machine_Learning en varios tipos de tareas de percepción y comprensión del lenguaje. Actualmente, diferentes equipos lo utilizan tanto para la investigación como para la producción en muchos productos comerciales de Google, como reconocimiento de voz, Gmail, Google Photos y búsqueda, muchos de los cuales habían utilizado anteriormente su predecesor DistBelief. TensorFlow fue desarrollado originalmente por el equipo de Google Brain para fines de investigación y producción de Google y luego se lanzó bajo la licencia de código abierto Apache 2.0 el 9 de noviembre de 2015.\n",
    "\n",
    "* [TensorFlow Homepage](https://www.tensorflow.org/)\n",
    "* [TensorFlow GitHib](https://github.com/tensorflow/tensorflow)\n",
    "* [TensorFlow Google Groups Support](https://groups.google.com/forum/#!forum/tensorflow)\n",
    "* [TensorFlow Google Groups Developer Discussion](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss)\n",
    "* [TensorFlow FAQ](https://www.tensorflow.org/resources/faq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zg-zNx0CtiN"
   },
   "source": [
    "## ¿Por qué TensorFlow?\n",
    "\n",
    "* Cuenta con el apoyo de Google\n",
    "* Funciona bien en Windows, Linux y Mac\n",
    "* Excelente soporte de GPU\n",
    "* Python es un lenguaje de programación fácil de aprender\n",
    "* Python es extremadamente popular en la comunidad de ciencia de datos\n",
    "\n",
    "## Deep Learning Tools\n",
    "TensorFlow no es el único juego de la ciudad. El mayor competidor de TensorFlow/Keras es PyTorch. A continuación se enumeran algunos de los kits de herramientas de aprendizaje profundo que se admiten activamente:\n",
    "\n",
    "* **[TensorFlow](https://www.tensorflow.org/)** - API de aprendizaje profundo de Google.\n",
    "* **[Keras](https://keras.io/)** - También de Google, framework de mayor nivel que permite el uso de TensorFlow, MXNet y Theano indistintamente.\n",
    "* **[PyTorch](https://pytorch.org/)** - PyTorch es una biblioteca de aprendizaje automático de código abierto basada en la biblioteca Torch, que se utiliza para aplicaciones como la visión artificial y el procesamiento del lenguaje natural. Está desarrollado principalmente por el laboratorio de investigación de IA de Facebook. \n",
    "\n",
    "Otros deep learning tools:\n",
    "\n",
    "* **[MXNet](https://mxnet.incubator.apache.org/)** API de aprendizaje profundo de la fundación Apache. Se puede utilizar a través de Keras.\n",
    "* **[Torch](http://torch.ch/)** es utilizado por Google DeepMind, Facebook AI Research Group, IBM, Yandex y el Idiap Research Institute. Se ha utilizado para algunos de los proyectos de aprendizaje profundo más avanzados del mundo.\n",
    "* **[PaddlePaddle](https://github.com/baidu/Paddle)** - [Baidu](http://www.baidu.com/)'s deep learning API.\n",
    "* **[Deeplearning4J](http://deeplearning4j.org/)** - Basado en Java. Soporta todas las plataformas principales. ¡Soporte de GPU en Java!\n",
    "* **[Computational Network Toolkit (CNTK)](https://github.com/Microsoft/CNTK)** -Microsoft. Soporte para Windows/Linux, solo línea de comando. Enlaces para predicciones para C#/Python. Soporte de GPU\n",
    "* **[H2O](http://www.h2o.ai/)** - Basado en Java. Soporta todas las plataformas principales. Soporte limitado para visión artificial. Sin soporte para GPU.\n",
    "\n",
    "## Uso TensorFlow Directamente\n",
    "\n",
    "La mayor parte del tiempo en el curso, nos comunicaremos con TensorFlow usando Keras, que le permite especificar el número de capas ocultas y crear la red neuronal. TensorFlow es una API matemática de bajo nivel, similar a [Numpy](http://www.numpy.org/).  Sin embargo, a diferencia de Numpy, TensorFlow está diseñado para el aprendizaje profundo. TensorFlow compila estos gráficos de cómputo en gráficos altamente eficientes C++/[CUDA](https://en.wikipedia.org/wiki/CUDA) code.\n",
    "\n",
    "### TensorFlow Ejemplos de álgebra lineal\n",
    "\n",
    "TensorFlow es una biblioteca para álgebra lineal. Keras es una abstracción de alto nivel para las redes neuronales que construyes sobre TensorFlow. En esta sección, demostraré algo de álgebra lineal básica que emplea TensorFlow directamente y no utiliza Keras. Primero, veremos cómo multiplicar una matriz de filas y columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkh9pHqPCtiO",
    "outputId": "c2b05474-0644-4c5c-c7fc-fb94e1e6a69d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[12.]], shape=(1, 1), dtype=float32)\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Cree una operación constante que produzca una matriz de 1x2. la operación es\n",
    "# agregado como un nodo al gráfico predeterminado.\n",
    "#\n",
    "# El valor devuelto por el constructor representa la salida\n",
    "# de la constante op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Cree otra constante que produzca una matriz de 2x1.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Cree una operación de Matmul que tome 'matrix1' y 'matrix2' como entradas.\n",
    "# El valor devuelto, 'producto', representa el resultado de la matriz\n",
    "# multiplicación.\n",
    "producto = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "print(producto)\n",
    "print(float(producto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMrXqwskCtiP"
   },
   "source": [
    "Este ejemplo multiplicó dos tensores constantes de TensorFlow. A continuación, veremos cómo restar una constante de una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKyFCaoTCtiP",
    "outputId": "3c75a8cf-8d1c-48df-fb71-f603053cf616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-2. -1.], shape=(2,), dtype=float32)\n",
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# Agregue una operación para restar 'a' de 'x'. Ejecútalo e imprime el resultado.\n",
    "sub = tf.subtract(x, a)\n",
    "print(sub)\n",
    "print(sub.numpy())\n",
    "# ==> [-2. -1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epQ9LrM6CtiP"
   },
   "source": [
    "Por supuesto, las variables solo son útiles si sus valores se pueden cambiar. El programa puede lograr este cambio de valor llamando a la función de asignación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtnW5aU-CtiP",
    "outputId": "77d3ae14-dfac-4877-dd7f-d30ae9c9751d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2,) dtype=float32, numpy=array([4., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.assign([4.0, 6.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHwJP8MjCtiQ"
   },
   "source": [
    "\n",
    "El programa ahora puede realizar la resta con este nuevo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e26Fe-GCtiQ",
    "outputId": "979cf4e5-4d6d-45e2-c7a7-c12e6b169baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 3.], shape=(2,), dtype=float32)\n",
      "[1. 3.]\n"
     ]
    }
   ],
   "source": [
    "sub = tf.subtract(x, a)\n",
    "print(sub)\n",
    "print(sub.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq61YFBYCtiQ"
   },
   "source": [
    "\n",
    "En la siguiente sección, veremos un ejemplo de TensorFlow que no tiene nada que ver con las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMVIS9pBCtiQ"
   },
   "source": [
    "### TensorFlow Mandelbrot Set Ejemplo\n",
    "\n",
    "A continuación, examinamos otro ejemplo en el que usamos TensorFlow directamente. Para demostrar que TensorFlow es matemático y no solo proporciona redes neuronales, también lo usaremos primero para una tarea de representación que no sea de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "v4ll1OLwCtiQ",
    "outputId": "e0f9479e-7bd7-4c4f-f8dc-b658a72ee747"
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importar librarias para la simulación\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Importar para visualización\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def DisplayFractal(a, fmt='jpeg'):\n",
    "  \"\"\"Muestra una matriz de recuentos de iteraciones como un\n",
    "     imagen colorida de un fractal.\"\"\"\n",
    "  a_cyclic = (6.28*a/20.0).reshape(list(a.shape)+[1])\n",
    "  img = np.concatenate([10+20*np.cos(a_cyclic),\n",
    "                        30+50*np.sin(a_cyclic),\n",
    "                        155-80*np.cos(a_cyclic)], 2)\n",
    "  img[a==a.max()] = 0\n",
    "  a = img\n",
    "  a = np.uint8(np.clip(a, 0, 255))\n",
    "  f = BytesIO()\n",
    "  PIL.Image.fromarray(a).save(f, fmt)\n",
    "  display(Image(data=f.getvalue()))\n",
    "\n",
    "# Use NumPy para crear una matriz 2D de números complejos\n",
    "\n",
    "Y, X = np.mgrid[-1.3:1.3:0.005, -2:1:0.005]\n",
    "Z = X+1j*Y\n",
    "\n",
    "xs = tf.constant(Z.astype(np.complex64))\n",
    "zs = tf.Variable(xs)\n",
    "ns = tf.Variable(tf.zeros_like(xs, tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(200):\n",
    "    # CCalcular los nuevos valores de z: z^2 + x\n",
    "    zs_ = zs*zs + xs\n",
    "\n",
    "    # ¿Hemos divergido con este nuevo valor?\n",
    "    not_diverged = tf.abs(zs_) < 4\n",
    "\n",
    "    zs.assign(zs_),\n",
    "    ns.assign_add(tf.cast(not_diverged, tf.float32))\n",
    "    \n",
    "DisplayFractal(ns.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtvjPq7HCtiQ"
   },
   "source": [
    "El renderizado de Mandlebrot es simple e infinitamente complejo al mismo tiempo. Esta vista muestra todo el universo de Mandlebrot al mismo tiempo, ya que está completamente alejado. Sin embargo, si hace zoom en cualquier parte del gráfico que no sea negra, encontrará una complejidad oculta infinita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeWypKgGCtiR"
   },
   "source": [
    "### Introducción a Keras\n",
    "\n",
    "[Keras](https://keras.io/) es una capa superior Tensorflow que facilita mucho la creación de redes neuronales. En lugar de definir los gráficos, como ve arriba, configura las capas individuales de la red con una API de mucho más alto nivel. A menos que esté realizando una investigación sobre estructuras completamente nuevas de redes neuronales profundas, es poco probable que necesite programar TensorFlow directamente.  \n",
    "\n",
    "**Para esta clase, usaremos TensorFlow a través de Keras, en lugar de TensorFlow directo.**\n",
    "\n",
    "### Simple regresión con TensorFlow: MPG\n",
    "\n",
    "Este ejemplo muestra cómo codificar el conjunto de datos MPG para la regresión. Este conjunto de datos es un poco más complicado que Iris, porque:\n",
    "\n",
    "* La entrada tiene tanto numérico como categórico\n",
    "* La entrada tiene valores faltantes\n",
    "\n",
    "Este ejemplo utiliza funciones definidas anteriormente en este notebook, las \"funciones_de_ayuda\". Estas funciones le permiten construir el vector de características para una red neuronal. Considera lo siguiente:\n",
    "\n",
    "* Predictores/Entradas\n",
    "    * Rellene las entradas faltantes con la mediana de esa columna. Utilice **missing_median**.\n",
    "    * Codifique valores textuales/categóricos con **encode_text_dummy**.\n",
    "    * Codifique valores numéricos con **encode_numeric_zscore**.\n",
    "* Producción\n",
    "    * Descartar filas con salidas faltantes.\n",
    "    * Codificar valores textuales/categóricos con **encode_text_index**.\n",
    "    * No codificar valores numéricos de salida.\n",
    "* Producir vectores de características finales (x) y salida esperada (y) con **to_xy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmb3cFrUCtiR",
    "outputId": "6aee69f2-aa06-411d-a7be-4362e4e35f7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 - 0s - loss: 222.1605 - 338ms/epoch - 26ms/step\n",
      "Epoch 2/100\n",
      "13/13 - 0s - loss: 180.5455 - 35ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "13/13 - 0s - loss: 153.6098 - 37ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "13/13 - 0s - loss: 130.1387 - 27ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "13/13 - 0s - loss: 119.5372 - 28ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "13/13 - 0s - loss: 116.7377 - 27ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "13/13 - 0s - loss: 110.6803 - 28ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "13/13 - 0s - loss: 89.0653 - 27ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "13/13 - 0s - loss: 91.8128 - 27ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "13/13 - 0s - loss: 80.1005 - 27ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "13/13 - 0s - loss: 76.2340 - 27ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "13/13 - 0s - loss: 75.6091 - 29ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "13/13 - 0s - loss: 69.3065 - 28ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "13/13 - 0s - loss: 71.4853 - 29ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "13/13 - 0s - loss: 66.0467 - 27ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "13/13 - 0s - loss: 62.6465 - 27ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "13/13 - 0s - loss: 61.1569 - 29ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "13/13 - 0s - loss: 63.1535 - 29ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "13/13 - 0s - loss: 56.4575 - 27ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "13/13 - 0s - loss: 55.2412 - 28ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "13/13 - 0s - loss: 67.2348 - 29ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "13/13 - 0s - loss: 55.2257 - 28ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "13/13 - 0s - loss: 51.3268 - 25ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "13/13 - 0s - loss: 51.0435 - 26ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "13/13 - 0s - loss: 48.3385 - 26ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "13/13 - 0s - loss: 52.1902 - 27ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "13/13 - 0s - loss: 47.4257 - 28ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "13/13 - 0s - loss: 42.8842 - 26ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "13/13 - 0s - loss: 45.1698 - 26ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "13/13 - 0s - loss: 41.4481 - 29ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "13/13 - 0s - loss: 43.3432 - 27ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "13/13 - 0s - loss: 42.4410 - 27ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "13/13 - 0s - loss: 39.0153 - 27ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "13/13 - 0s - loss: 35.8444 - 29ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "13/13 - 0s - loss: 35.7594 - 28ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "13/13 - 0s - loss: 39.0856 - 25ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "13/13 - 0s - loss: 32.7899 - 27ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "13/13 - 0s - loss: 32.7375 - 27ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "13/13 - 0s - loss: 31.5079 - 26ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "13/13 - 0s - loss: 31.8339 - 27ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "13/13 - 0s - loss: 33.0880 - 27ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "13/13 - 0s - loss: 32.7778 - 27ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "13/13 - 0s - loss: 31.7688 - 27ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "13/13 - 0s - loss: 29.4838 - 26ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "13/13 - 0s - loss: 27.2980 - 26ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "13/13 - 0s - loss: 30.9054 - 26ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "13/13 - 0s - loss: 32.1735 - 26ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "13/13 - 0s - loss: 29.2739 - 28ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "13/13 - 0s - loss: 30.3687 - 27ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "13/13 - 0s - loss: 29.4328 - 29ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "13/13 - 0s - loss: 29.0355 - 28ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "13/13 - 0s - loss: 29.5401 - 26ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "13/13 - 0s - loss: 29.3918 - 26ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "13/13 - 0s - loss: 27.3136 - 27ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "13/13 - 0s - loss: 24.2287 - 25ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "13/13 - 0s - loss: 23.4046 - 28ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "13/13 - 0s - loss: 20.5952 - 28ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "13/13 - 0s - loss: 24.3264 - 27ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "13/13 - 0s - loss: 22.3732 - 27ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "13/13 - 0s - loss: 22.1820 - 26ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "13/13 - 0s - loss: 19.5460 - 27ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "13/13 - 0s - loss: 19.4362 - 27ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "13/13 - 0s - loss: 20.1538 - 26ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "13/13 - 0s - loss: 19.7124 - 27ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "13/13 - 0s - loss: 19.6789 - 27ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "13/13 - 0s - loss: 19.1720 - 27ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "13/13 - 0s - loss: 17.7774 - 27ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "13/13 - 0s - loss: 19.7083 - 25ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "13/13 - 0s - loss: 17.9111 - 27ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "13/13 - 0s - loss: 17.8039 - 28ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "13/13 - 0s - loss: 18.8381 - 26ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "13/13 - 0s - loss: 22.3139 - 26ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "13/13 - 0s - loss: 21.1366 - 26ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "13/13 - 0s - loss: 18.2714 - 26ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "13/13 - 0s - loss: 19.5166 - 29ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "13/13 - 0s - loss: 15.6772 - 27ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "13/13 - 0s - loss: 15.3693 - 26ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "13/13 - 0s - loss: 15.8950 - 27ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "13/13 - 0s - loss: 15.9585 - 26ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "13/13 - 0s - loss: 15.4450 - 27ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "13/13 - 0s - loss: 15.9803 - 26ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "13/13 - 0s - loss: 14.8226 - 28ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "13/13 - 0s - loss: 15.6912 - 31ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "13/13 - 0s - loss: 15.1614 - 30ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "13/13 - 0s - loss: 23.2221 - 27ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "13/13 - 0s - loss: 18.4139 - 26ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "13/13 - 0s - loss: 14.8690 - 27ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "13/13 - 0s - loss: 16.3692 - 28ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "13/13 - 0s - loss: 15.8527 - 28ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "13/13 - 0s - loss: 14.3196 - 27ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "13/13 - 0s - loss: 14.3914 - 26ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "13/13 - 0s - loss: 15.4478 - 26ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "13/13 - 0s - loss: 15.7441 - 27ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "13/13 - 0s - loss: 13.8905 - 26ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "13/13 - 0s - loss: 15.0788 - 28ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "13/13 - 0s - loss: 13.5361 - 30ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "13/13 - 0s - loss: 14.5157 - 27ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "13/13 - 0s - loss: 14.1823 - 26ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "13/13 - 0s - loss: 15.1221 - 27ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "13/13 - 0s - loss: 13.8903 - 27ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2429a166388>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "cars = df['name']\n",
    "\n",
    "# Tratado de missing value\n",
    "df['horsepower'] = df['horsepower'].fillna(df['horsepower'].median())\n",
    "\n",
    "# Pandas a Numpy\n",
    "x = df[['cylinders', 'displacement', 'horsepower', 'weight',\n",
    "       'acceleration', 'year', 'origin']].values\n",
    "y = df['mpg'].values # regression\n",
    "\n",
    "# Construir la red neural\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=x.shape[1], activation='relu')) # Oculta 1\n",
    "model.add(Dense(10, activation='relu')) # Oculta 2\n",
    "model.add(Dense(1)) # Salida\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82O2rvqiCtiR"
   },
   "source": [
    "### Introducción a los hiperparámetros de redes neuronales\n",
    "\n",
    "Si observa el código anterior, verá que la red neuronal contiene cuatro capas. La primera capa es la capa de entrada porque contiene el parámetro **input_dim** que el programador establece como el número de entradas que tiene el conjunto de datos. La red necesita una neurona de entrada para cada columna del dataset (incluidas las variables ficticias).\n",
    "\n",
    "También hay varias capas ocultas, con 25 y 10 neuronas cada una. Quizás se pregunte cómo el programador eligió estos números. Seleccionar una estructura neuronal oculta es una de las preguntas más comunes sobre las redes neuronales. Desafortunadamente, no hay una respuesta correcta. Estos son hiperparámetros. Son configuraciones que pueden afectar el rendimiento de la red neuronal, pero no hay un medio claramente definido para configurarlas.\n",
    "\n",
    "En general, más neuronas ocultas significan más capacidad para adaptarse a problemas complejos. Sin embargo, demasiadas neuronas pueden provocar Overfitting y largos tiempos de entrenamiento. Muy pocos pueden dar lugar a una adaptación insuficiente del problema y sacrificarán la precisión. Además, cuántas capas tiene es otro hiperparámetro. En general, más capas permiten que la red neuronal pueda realizar más de su ingeniería de características y preprocesamiento de datos. Pero esto también se produce a expensas de los tiempos de entrenamiento y el riesgo de Overfitting. En general, verá que los recuentos de neuronas comienzan más cerca de la capa de entrada y tienden a reducirse hacia la capa de salida en una especie de forma triangular.\n",
    "\n",
    "### Controlar la cantidad de salida\n",
    "\n",
    "El programa produce una línea de salida para cada época de entrenamiento. Puede eliminar esta salida configurando la configuración detallada del comando de ajuste:\n",
    "\n",
    "* **verbose=0** - Sin salida de progreso (utilice con Jupyter si no desea salida)\n",
    "* **verbose=1** - Muestra la barra de progreso, no funciona bien con Jupyter\n",
    "* **verbose=2** - Resumen de resultados de progreso (úselo con Jupyter si desea conocer la pérdida en cada época)\n",
    "\n",
    "### Predicción de regresión\n",
    "\n",
    "A continuación, realizaremos predicciones reales. El programa asigna estas predicciones a la variable **pred**. Estas son todas las predicciones de MPG de la red neuronal. ¿Observe que se trata de una matriz 2D? Siempre puede ver las dimensiones de lo que Keras devuelve imprimiendo **pred.shape**. Las redes neuronales pueden devolver múltiples valores, por lo que el resultado siempre es una matriz. Aquí, la red neuronal solo devuelve un valor por predicción (hay 398 autos, por lo que 398 predicciones). Sin embargo, se necesita un rango 2D porque la red neuronal tiene el potencial de devolver más de un valor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbErLyX_CtiR",
    "outputId": "d3ee0abe-e5b6-4575-8f7f-666a868e0e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (398, 1)\n",
      "[[15.588783]\n",
      " [15.046434]\n",
      " [16.291985]\n",
      " [16.862738]\n",
      " [15.839203]\n",
      " [10.71751 ]\n",
      " [10.811102]\n",
      " [10.873663]\n",
      " [10.921455]\n",
      " [13.424355]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(f\"Shape: {pred.shape}\")\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk_lWnScCtiR"
   },
   "source": [
    "Nos gustaría ver qué tan buenas son estas predicciones. Sabemos cuál es el MPG correcto para cada automóvil, por lo que podemos medir qué tan cerca estaba la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrY0Vs9oCtiR",
    "outputId": "3be93e76-a814-4349-8907-ef9125938a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score (RMSE): 3.6251872357964077\n"
     ]
    }
   ],
   "source": [
    "# Medir error RMSE. RMSE es común para la regresión.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3yqZwhnCtiS"
   },
   "source": [
    "El número impreso arriba es la cantidad promedio en la que las predicciones estuvieron por encima o por debajo del resultado esperado. También podemos imprimir los primeros diez autos, con predicciones y MPG real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tl7hv8NnCtiS",
    "outputId": "742d6cac-12d6-43a9-d442-64cd8e3e4523"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nombre del Coche: chevrolet chevelle malibu, MPG: 18.0, predicted MPG: [15.588783]\n",
      "2. Nombre del Coche: buick skylark 320, MPG: 15.0, predicted MPG: [15.046434]\n",
      "3. Nombre del Coche: plymouth satellite, MPG: 18.0, predicted MPG: [16.291985]\n",
      "4. Nombre del Coche: amc rebel sst, MPG: 16.0, predicted MPG: [16.862738]\n",
      "5. Nombre del Coche: ford torino, MPG: 17.0, predicted MPG: [15.839203]\n",
      "6. Nombre del Coche: ford galaxie 500, MPG: 15.0, predicted MPG: [10.71751]\n",
      "7. Nombre del Coche: chevrolet impala, MPG: 14.0, predicted MPG: [10.811102]\n",
      "8. Nombre del Coche: plymouth fury iii, MPG: 14.0, predicted MPG: [10.873663]\n",
      "9. Nombre del Coche: pontiac catalina, MPG: 14.0, predicted MPG: [10.921455]\n",
      "10. Nombre del Coche: amc ambassador dpl, MPG: 15.0, predicted MPG: [13.424355]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplos de predicciones\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. Nombre del Coche: {cars[i]}, MPG: {y[i]}, \" \n",
    "          + f\"predicted MPG: {pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_dpgVtfCtiS"
   },
   "source": [
    "### Clasificación simple de TensorFlow: Iris\n",
    "\n",
    "La clasificación es el proceso mediante el cual una red neuronal intenta clasificar la entrada en una o más clases. La forma más sencilla de evaluar una red de clasificación es rastrear el porcentaje de elementos del conjunto de entrenamiento que se clasificaron incorrectamente. Por lo general, calificamos los resultados humanos de esta manera. Por ejemplo, es posible que haya realizado exámenes de opción múltiple en la escuela en los que tuvo que sombrear una burbuja para las opciones A, B, C o D. Si elige la letra incorrecta en un examen de 10 preguntas, obtendrá un 90%. De la misma manera, podemos calificar las computadoras; sin embargo, la mayoría de los algoritmos de clasificación no eligen simplemente A, B, C o D. Las computadoras generalmente informan una clasificación como su porcentaje de confianza en cada clase. La Figura 3.EXAM muestra cómo una computadora y un ser humano podrían responder a la pregunta número 1 en un examen.\n",
    "\n",
    "**Figure 3.EXAM: Classification Neural Network Output**\n",
    "![Classification Neural Network Output](images/class-multi-choice.png \"Classification Neural Network Output\")\n",
    "\n",
    "Como puede ver, el examinador humano marcó la primera pregunta como \"B\". Sin embargo, el examinado por computadora tenía un 80 % (0,8) de confianza en \"B\" y también estaba algo seguro con un 10 % (0,1) en \"A\". Luego, la computadora distribuyó los puntos restantes en los otros dos. En el sentido más simple, la máquina obtendría el 80 % de la puntuación de esta pregunta si la respuesta correcta fuera \"B\". La computadora obtendría solo el 5% (0.05) de los puntos si la respuesta correcta fuera \"D\".\n",
    "\n",
    "Lo que acabamos de ver es un ejemplo sencillo de cómo realizar la clasificación de Iris usando TensorFlow. Se usa el archivo iris.csv, en lugar de usar los datos integrados que requieren muchos de los ejemplos de Google.  \n",
    "\n",
    "**Asegúrese de ejecutar siempre bloques de código anteriores. Si ejecuta el bloque de código a continuación, sin el bloque de código anterior, obtendrá errores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLp65T9JCtiS",
    "outputId": "cc56ca71-b7cf-41ff-afbe-76cbb465dcca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 0s - loss: 1.3552 - 242ms/epoch - 48ms/step\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 1.1389 - 15ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "5/5 - 0s - loss: 1.0251 - 16ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.9514 - 17ms/epoch - 3ms/step\n",
      "Epoch 5/100\n",
      "5/5 - 0s - loss: 0.8955 - 16ms/epoch - 3ms/step\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.8420 - 18ms/epoch - 4ms/step\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.7980 - 17ms/epoch - 3ms/step\n",
      "Epoch 8/100\n",
      "5/5 - 0s - loss: 0.7535 - 16ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.7139 - 17ms/epoch - 3ms/step\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.6757 - 18ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.6411 - 16ms/epoch - 3ms/step\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.6102 - 13ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.5808 - 12ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "5/5 - 0s - loss: 0.5562 - 13ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "5/5 - 0s - loss: 0.5341 - 12ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.5139 - 13ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.4955 - 11ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.4781 - 13ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.4616 - 14ms/epoch - 3ms/step\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.4473 - 14ms/epoch - 3ms/step\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.4347 - 12ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.4221 - 12ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.4083 - 10ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.3967 - 11ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.3845 - 10ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.3745 - 12ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.3629 - 12ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.3547 - 11ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.3415 - 13ms/epoch - 3ms/step\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.3340 - 11ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.3200 - 10ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.3113 - 11ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "5/5 - 0s - loss: 0.3000 - 11ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.2918 - 12ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.2809 - 11ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.2732 - 11ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.2629 - 12ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.2555 - 11ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "5/5 - 0s - loss: 0.2467 - 11ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "5/5 - 0s - loss: 0.2427 - 12ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.2311 - 10ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.2216 - 11ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 0.2098 - 11ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 0.2034 - 11ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.1952 - 10ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 0.1886 - 11ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.1829 - 11ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 0.1776 - 11ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "5/5 - 0s - loss: 0.1718 - 12ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "5/5 - 0s - loss: 0.1676 - 11ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "5/5 - 0s - loss: 0.1618 - 12ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 0.1570 - 11ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 0.1534 - 11ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "5/5 - 0s - loss: 0.1495 - 11ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 0.1462 - 11ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 0.1444 - 12ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "5/5 - 0s - loss: 0.1389 - 11ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "5/5 - 0s - loss: 0.1364 - 12ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "5/5 - 0s - loss: 0.1339 - 10ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "5/5 - 0s - loss: 0.1301 - 11ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "5/5 - 0s - loss: 0.1270 - 12ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "5/5 - 0s - loss: 0.1247 - 12ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "5/5 - 0s - loss: 0.1223 - 11ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "5/5 - 0s - loss: 0.1202 - 12ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "5/5 - 0s - loss: 0.1175 - 12ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 0.1167 - 12ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "5/5 - 0s - loss: 0.1136 - 11ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 0.1120 - 11ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "5/5 - 0s - loss: 0.1098 - 13ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "5/5 - 0s - loss: 0.1084 - 12ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "5/5 - 0s - loss: 0.1080 - 12ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "5/5 - 0s - loss: 0.1056 - 10ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 0.1059 - 11ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "5/5 - 0s - loss: 0.1062 - 10ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "5/5 - 0s - loss: 0.1010 - 11ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "5/5 - 0s - loss: 0.1013 - 11ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "5/5 - 0s - loss: 0.0993 - 12ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "5/5 - 0s - loss: 0.0987 - 11ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "5/5 - 0s - loss: 0.0973 - 12ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 0.0964 - 11ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "5/5 - 0s - loss: 0.0972 - 12ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "5/5 - 0s - loss: 0.0948 - 11ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 0.0939 - 11ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "5/5 - 0s - loss: 0.0915 - 12ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "5/5 - 0s - loss: 0.0930 - 10ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "5/5 - 0s - loss: 0.0902 - 12ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "5/5 - 0s - loss: 0.0919 - 17ms/epoch - 3ms/step\n",
      "Epoch 88/100\n",
      "5/5 - 0s - loss: 0.0914 - 13ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "5/5 - 0s - loss: 0.0881 - 12ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "5/5 - 0s - loss: 0.0870 - 12ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "5/5 - 0s - loss: 0.0884 - 11ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "5/5 - 0s - loss: 0.0848 - 11ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "5/5 - 0s - loss: 0.0846 - 11ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "5/5 - 0s - loss: 0.0832 - 11ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "5/5 - 0s - loss: 0.0826 - 10ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "5/5 - 0s - loss: 0.0824 - 11ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "5/5 - 0s - loss: 0.0805 - 11ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 0.0850 - 12ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 0.0798 - 12ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 0.0799 - 11ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2429dcbc448>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x = df[['sepal_l', 'sepal_w', 'petal_l', 'petal_w']].values\n",
    "dummies = pd.get_dummies(df['species']) # Classificación\n",
    "species = dummies.columns\n",
    "y = dummies.values\n",
    "\n",
    "\n",
    "# Construir la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Oculta 1\n",
    "model.add(Dense(25, activation='relu')) # Oculta 2\n",
    "model.add(Dense(y.shape[1],activation='softmax')) # Salida\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(x,y,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPM30WdBCtiS",
    "outputId": "a02c3d4e-239f-44b2-bb1f-f8904114ac29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imprimir el número de especies encontradas:\n",
    "\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM8-xyDxCtiS"
   },
   "source": [
    "Ahora que tiene un entrenamiento de red neuronal, nos gustaría poder usarlo. El siguiente código hace uso de nuestra red neuronal. Exactamente como antes, generaremos predicciones. Observe que vuelven tres valores para cada una de las 150 flores de iris. Había tres tipos de iris (Iris-setosa, Iris-versicolor e Iris-virginica)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YzlVpw-CtiS",
    "outputId": "a253eb73-5a42-4276-87f7-c287bdc52edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (150, 3)\n",
      "[[9.96728659e-01 3.27128102e-03 2.53017216e-08]\n",
      " [9.91585255e-01 8.41462333e-03 1.49150893e-07]\n",
      " [9.94830191e-01 5.16966265e-03 9.47089234e-08]\n",
      " [9.90646124e-01 9.35364701e-03 2.78289463e-07]\n",
      " [9.97087419e-01 2.91259773e-03 2.45902338e-08]\n",
      " [9.96406496e-01 3.59352934e-03 2.21737206e-08]\n",
      " [9.94559228e-01 5.44067845e-03 1.30652865e-07]\n",
      " [9.95159090e-01 4.84086853e-03 5.43411645e-08]\n",
      " [9.88472879e-01 1.15266778e-02 5.21418315e-07]\n",
      " [9.92857814e-01 7.14205066e-03 1.06054294e-07]]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x)\n",
    "print(f\"Shape: {pred.shape}\")\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCay-JrvCtiS"
   },
   "source": [
    "Si desea desactivar la notación científica, puede utilizar la siguiente línea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nXZne7ZICtiS"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOvMqI7QCtiS"
   },
   "source": [
    "Ahora vemos estos valores redondeados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9PSDexjCtiS",
    "outputId": "cce7841f-4c30-45d6-f80a-ee886986844b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(y[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDC7hxqECtiS"
   },
   "source": [
    "Por lo general, el programa considera que la columna con la predicción más alta es la predicción de la red neuronal. Es fácil convertir las predicciones a las especies de iris esperadas. La función argmax encuentra el índice de la predicción máxima para cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "367mbx_PCtiT",
    "outputId": "ea639c6e-7ba5-404e-afb9-8921e0891dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Expected: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "predict_classes = np.argmax(pred,axis=1)\n",
    "expected_classes = np.argmax(y,axis=1)\n",
    "print(f\"Predictions: {predict_classes}\")\n",
    "print(f\"Expected: {expected_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrcy0Q4xCtiT"
   },
   "source": [
    "Por supuesto, es sencillo volver a convertir estos índices en especies de iris. Usamos la lista de especies que creamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTORTvygCtiT",
    "outputId": "93b065ef-9c84-4103-992c-a77fe7be8519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
      "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
      "       'Iris-setosa'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(species[predict_classes[1:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ljez1ZRACtiT"
   },
   "source": [
    "La precisión podría ser una métrica de error más fácil de entender. Es esencialmente un puntaje de prueba. Para todas las predicciones del iris, ¿qué porcentaje fue correcto? La desventaja es que no considera la confianza de la red neuronal en cada predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zth2S2OcCtiT",
    "outputId": "245de0c3-22c8-4337-c631-a2967a8d44d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "correct = accuracy_score(expected_classes,predict_classes)\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY07aiLICtiT"
   },
   "source": [
    "El siguiente código realiza dos predicciones ad hoc. La primera predicción es simplemente una sola flor de iris y la segunda predice dos flores de iris. ¿Observe que el argmax en la segunda predicción requiere **axis=1**? Dado que ahora tenemos una matriz 2D, debemos especificar qué eje tomará el argmax. El valor **axis=1** especifica que queremos el índice de columna máximo para cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZUSWVGnCtiT",
    "outputId": "3a38bf92-837c-469e-a672-8c7f53894650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00051492 0.17222434 0.8272607 ]]\n",
      "La predicción parea [[5. 3. 4. 2.]] is: Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "ejemplo_flor = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
    "pred = model.predict(ejemplo_flor)\n",
    "print(pred)\n",
    "pred = np.argmax(pred)\n",
    "print(f\"La predicción parea {ejemplo_flor} is: {species[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENSZaaRICtiT"
   },
   "source": [
    "\n",
    "También puede predecir dos flores de muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSSkkmwCtiT",
    "outputId": "2be33dec-832b-445f-dc82-35181e7932a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00051492 0.17222425 0.8272608 ]\n",
      " [0.9890956  0.01090409 0.00000023]]\n",
      "La predicción para las dos flores [[5.  3.  4.  2. ]\n",
      " [5.2 3.5 1.5 0.8]] \n",
      "Es: Index(['Iris-virginica', 'Iris-setosa'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "ejemplo_flor = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]],\\\n",
    "        dtype=float)\n",
    "pred = model.predict(ejemplo_flor)\n",
    "print(pred)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "print(f\"La predicción para las dos flores {ejemplo_flor} \")\n",
    "print(f\"Es: {species[pred]}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of t81_558_class_03_2_keras.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "129c28eb7371f81f3b772b69408a02d1e141a0d5c957c78df09fa0d1b2bc4f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
