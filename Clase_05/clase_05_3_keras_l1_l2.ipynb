{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modulo 5 : Regularización y Dropout**\n",
    "* Instructor: [Juan Maniglia](https://juanmaniglia.github.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5.3: Regularización L1 y L2 para Disminuir _Overfitting_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regularización L1 y L2 son dos técnicas de regularización comunes que pueden reducir los efectos del sobreajuste. Ambos algoritmos pueden funcionar con una función objetivo o como parte del algoritmo de retropropagación. En ambos casos el algoritmo de regularización se adjunta al algoritmo de entrenamiento añadiendo un objetivo adicional.\n",
    "\n",
    "Ambos algoritmos funcionan agregando una penalización de peso al entrenamiento de la red neuronal. Esta penalización anima a la red neuronal a mantener los pesos en valores pequeños. Tanto L1 como L2 calculan esta penalización de manera diferente. Para los algoritmos basados ​​en descenso de gradientes, como la retropropagación, puede agregar este cálculo de penalización a los gradientes calculados. Para el entrenamiento basado en funciones objetivas, como el recocido simulado, la penalización se combina negativamente con la puntuación objetiva.\n",
    "\n",
    "Tanto L1 como L2 funcionan de manera diferente en la forma en que penalizan el tamaño de un peso. L2 obligará a los pesos a adoptar un patrón similar a una distribución gaussiana; el L1 forzará los pesos en un patrón similar a una distribución de Laplace, como se muestra en la Figura 5.L1L2.\n",
    "\n",
    "**Figure 5.L1L2: L1 vs L2**\n",
    "![L1 vs L2](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_9_l1_l2.png \"L1 vs L2\")\n",
    "\n",
    "Como puede ver, el algoritmo L1 es más tolerante con los pesos más allá de 0, mientras que el algoritmo L2 es menos tolerante. Destacaremos otras diferencias importantes entre L1 y L2 en las siguientes secciones. También debe tener en cuenta que tanto L1 como L2 cuentan sus penalizaciones basándose únicamente en los pesos; no cuentan las penalizaciones sobre los valores de sesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data set\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en 'income'\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Clasificación\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (accuracy): 0.635\n",
      "Fold #2\n",
      "Fold score (accuracy): 0.705\n",
      "Fold #3\n",
      "Fold score (accuracy): 0.6725\n",
      "Fold #4\n",
      "Fold score (accuracy): 0.65\n",
      "Fold #5\n",
      "Fold score (accuracy): 0.64\n",
      "Final score (accuracy): 0.6605\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Regresión con L1/L2 Utilizando Keras\n",
    "########################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    #kernel_regularizer=regularizers.l2(0.01),\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], \n",
    "            activation='relu',\n",
    "             activity_regularizer=regularizers.l1(1e-4))) # Oculta 1\n",
    "    model.add(Dense(25, activation='relu', \n",
    "                    activity_regularizer=regularizers.l1(1e-4))) # Oculta 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Salida\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0,epochs=500)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    # probabilidades brutas a la clase elegida (probabilidad más alta)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    oos_pred.append(pred)        \n",
    "\n",
    "    # fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # accuracy\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "\n",
    "# Cree la lista de predicción oos y calcule el error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # accuracy\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "129c28eb7371f81f3b772b69408a02d1e141a0d5c957c78df09fa0d1b2bc4f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
