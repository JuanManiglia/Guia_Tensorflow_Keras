{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modulo 5 : Regularización y Dropout**\n",
    "* Instructor: [Juan Maniglia](https://juanmaniglia.github.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5.2: Uso de K-Fold Cross-validation con Keras\n",
    "\n",
    "La validación cruzada se puede utilizar para una variedad de propósitos en el modelado predictivo. Éstas incluyen:\n",
    "\n",
    "* Generación de predicciones fuera de la muestra a partir de una red neuronal\n",
    "* Estime una buena cantidad de épocas para entrenar una red neuronal (parada temprana)\n",
    "* Evaluar la efectividad de ciertos hiperparámetros, como funciones de activación, recuentos de neuronas y recuentos de capas\n",
    "\n",
    "La validación cruzada utiliza varios pliegues y múltiples modelos para proporcionar a cada segmento de datos la oportunidad de servir como conjunto de validación y entrenamiento. La validación cruzada se muestra en la Figura 5.CROSS.\n",
    "\n",
    "**Figure 5.CROSS: K-Fold Crossvalidation**\n",
    "![K-Fold Crossvalidation](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_1_kfold.png \"K-Fold Crossvalidation\")\n",
    "\n",
    "Es importante señalar que habrá un modelo (red neuronal) para cada pliegue. Para generar predicciones para nuevos datos, que son datos que no están presentes en el conjunto de entrenamiento, las predicciones de los modelos de pliegue se pueden manejar de varias maneras:\n",
    "\n",
    "* Elija el modelo que tuvo el puntaje de validación más alto como modelo final.\n",
    "* Preestablecer nuevos datos a los 5 modelos (uno para cada pliegue) y promediar el resultado.\n",
    "* Vuelva a entrenar un nuevo modelo (usando la misma configuración que la validación cruzada) en todo el conjunto de datos. Entrena para tantas épocas y con la misma estructura de capas ocultas.\n",
    "\n",
    "En general, prefiero el último enfoque y volveré a entrenar un modelo en todo el conjunto de datos una vez que haya seleccionado los hiperparámetros. Por supuesto, siempre reservaré un conjunto final de reserva para la validación del modelo que no uso en ningún aspecto del proceso de capacitación.\n",
    "\n",
    "### Regresión vs Clasificación K-Fold Cross-Validation\n",
    "\n",
    "La regresión y la clasificación se manejan de manera algo diferente con respecto a la validación cruzada. La regresión es el caso más simple en el que simplemente puede dividir el conjunto de datos en K pliegues sin tener en cuenta dónde cae cada elemento. Para la regresión, es mejor que los elementos de datos caigan en los pliegues de la forma más aleatoria posible. También es importante recordar que no todos los pliegues necesariamente tendrán exactamente la misma cantidad de elementos de datos. No siempre es posible que el conjunto de datos se divida uniformemente en K pliegues. Para la validación cruzada de regresión, usaremos la clase Scikit-Learn **KFold**.\n",
    "\n",
    "La validación cruzada para la clasificación también podría usar el objeto **KFold**; sin embargo, esta técnica no garantizaría que el equilibrio de clases permanezca igual en cada pliegue que en el original. Es muy importante que el equilibrio de las clases en las que se entrenó un modelo siga siendo el mismo (o similar) al conjunto de entrenamiento. Una desviación en esta distribución es una de las cosas más importantes para monitorear después de que un modelo entrenado se haya puesto en uso real. Debido a esto, queremos asegurarnos de que la validación cruzada en sí misma no introduzca un cambio no deseado. Esto se conoce como muestreo estratificado y se logra mediante el uso del objeto de Scikit-Learn **StratifiedKFold** en lugar de **KFold** siempre que utilice la clasificación. En resumen, se deben usar los siguientes dos objetos en Scikit-Learn:\n",
    "\n",
    "* **KFold** Cuando se trata de un problema de regresión.\n",
    "* **StratifiedKFold** Cuando se trata de un problema de clasificación.\n",
    "\n",
    "Las siguientes dos secciones demuestran la validación cruzada con clasificación y regresión.\n",
    "\n",
    "### Predicciones de regresión fuera de la muestra con validación cruzada K-Fold\n",
    "\n",
    "El siguiente código entrena el conjunto de datos simple mediante una validación cruzada de 5 veces. El rendimiento esperado de una red neuronal, del tipo entrenado aquí, sería la puntuación de las predicciones generadas fuera de la muestra. Comenzamos preparando un vector de características utilizando el jh-simple-dataset para predecir la edad. Este es un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'product'\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se ha creado el vector de características, se puede realizar una validación cruzada de 5 veces para generar predicciones fuera de la muestra. Asumiremos 500 épocas y no utilizaremos la detención anticipada. Más adelante veremos cómo podemos estimar un recuento de épocas más óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Score (RMSE): 0.6360556933488891\n",
      "Fold #2\n",
      "Score (RMSE): 0.4982818207521656\n",
      "Fold #3\n",
      "Score (RMSE): 0.6298677032008315\n",
      "Fold #4\n",
      "Score (RMSE): 0.4894054970459144\n",
      "Fold #5\n",
      "Score (RMSE): 1.1284291876751646\n",
      "Final, score (RMSE): 0.7158847831327483\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# Cross-Validate\n",
    "kf = KFold(5, shuffle=True, random_state=42) # Uso para KFold in clasificación\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "\n",
    "fold = 0\n",
    "for train, test in kf.split(x):\n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,\n",
    "              epochs=EPOCHS)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)    \n",
    "\n",
    "    # RMSE\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Score (RMSE): {score}\")\n",
    "\n",
    "# Cree la lista de predicción oos y calcule el error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print(f\"Final, score (RMSE): {score}\")    \n",
    "    \n",
    "# cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False) # para crear un archivo .csv con el dataframe anterior\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, el código anterior también informa la cantidad promedio de épocas necesarias. Una técnica común es entrenar luego en todo el conjunto de datos para el número promedio de épocas necesarias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación con Stratified K-Fold Cross-Validation\n",
    "\n",
    "El siguiente código entrena y ajusta el conjunto de datos jh-simple-dataset con validación cruzada para generar archivos fuera de muestra. También escribe los resultados de fuera de muestra (predicciones en el conjunto de prueba).\n",
    "\n",
    "Es bueno realizar una validación cruzada estratificada de k-fold con datos de clasificación. Esto asegura que los porcentajes de cada clase permanezcan iguales en todos los pliegues. Para ello, utilice el objeto **StratifiedKFold**, en lugar del objeto **KFold** utilizado en la regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Clasificación\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumiremos 500 épocas y no utilizaremos la detención anticipada. Más adelante veremos cómo podemos estimar un recuento de épocas más óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (accuracy): 0.6425\n",
      "Fold #2\n",
      "Fold score (accuracy): 0.6675\n",
      "Fold #3\n",
      "Fold score (accuracy): 0.675\n",
      "Fold #4\n",
      "Fold score (accuracy): 0.67\n",
      "Fold #5\n",
      "Fold score (accuracy): 0.6525\n",
      "Final score (accuracy): 0.6615\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "# np.argmax(pred,axis=1)\n",
    "# Cross-validate\n",
    "# Uso para StratifiedKFold clasificación\n",
    "kf = StratifiedKFold(5, shuffle=True, random_state=42) \n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "\n",
    "# Más especifico y StratifiedKFold 'for'\n",
    "for train, test in kf.split(x,df['product']):  \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Oculta 1\n",
    "    model.add(Dense(25, activation='relu')) # Oculta 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Salida\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),verbose=0,\\\n",
    "              epochs=EPOCHS)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    # probabilidades brutas a la clase elegida (probabilidad más alta)\n",
    "    pred = np.argmax(pred,axis=1) \n",
    "    oos_pred.append(pred)  \n",
    "\n",
    "    # fold's accuracy\n",
    "    y_compare = np.argmax(y_test,axis=1) # para accuracy\n",
    "    score = metrics.accuracy_score(y_compare, pred)\n",
    "    print(f\"Fold score (accuracy): {score}\")\n",
    "\n",
    "# Crear la lista de predicción oos y calcule el error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "oos_y_compare = np.argmax(oos_y,axis=1) # para accuracy\n",
    "\n",
    "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
    "print(f\"Final score (accuracy): {score}\")    \n",
    "    \n",
    "# cross-validated prediction\n",
    "oos_y = pd.DataFrame(oos_y)\n",
    "oos_pred = pd.DataFrame(oos_pred)\n",
    "oosDF = pd.concat( [df, oos_y, oos_pred],axis=1 )\n",
    "#oosDF.to_csv(filename_write,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento con una validación cruzada y un conjunto de reserva\n",
    "\n",
    "Si tiene una cantidad considerable de datos, siempre es valioso reservar un conjunto reservado antes de realizar una validación cruzada. Este conjunto de espera será la evaluación final antes de utilizar su modelo para su uso en el mundo real. La figura 5.HOLDOUT muestra esta división.\n",
    "\n",
    "**Figure 5.HOLDOUT: Cross Validation and a Holdout Set**\n",
    "![Cross Validation and a Holdout Set](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_3_hold_train_val.png \"Cross Validation and a Holdout Set\")\n",
    "\n",
    "El siguiente programa hace uso de un conjunto reservado y, a continuación, realiza una validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'product'\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que los datos han sido preprocesados, estamos listos para construir la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 0.9962207754668798\n",
      "Fold #2\n",
      "Fold score (RMSE): 0.5487815850145982\n",
      "Fold #3\n",
      "Fold score (RMSE): 0.6297824164503693\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.9789819627753718\n",
      "Fold #5\n",
      "Fold score (RMSE): 0.5684672822848418\n",
      "\n",
      "Cross-validated score (RMSE): 0.7709479474077178\n",
      "Holdout score (RMSE): 0.539625763275413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Mantenga una retención del 10%\n",
    "x_main, x_holdout, y_main, y_holdout = train_test_split(    \n",
    "    x, y, test_size=0.10) \n",
    "\n",
    "\n",
    "# Cross-validate\n",
    "kf = KFold(5)\n",
    "    \n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "for train, test in kf.split(x_main):        \n",
    "    fold+=1\n",
    "    print(f\"Fold #{fold}\")\n",
    "        \n",
    "    x_train = x_main[train]\n",
    "    y_train = y_main[train]\n",
    "    x_test = x_main[test]\n",
    "    y_test = y_main[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              verbose=0,epochs=EPOCHS)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred) \n",
    "\n",
    "    # accuracy\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(f\"Fold score (RMSE): {score}\")\n",
    "\n",
    "\n",
    "# Crear la lista de predicción oos y calcule el error.\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = np.sqrt(metrics.mean_squared_error(oos_pred,oos_y))\n",
    "print()\n",
    "print(f\"Cross-validated score (RMSE): {score}\")    \n",
    "    \n",
    "# Escriba la predicción con validación cruzada (de la última red neuronal)\n",
    "holdout_pred = model.predict(x_holdout)\n",
    "\n",
    "score = np.sqrt(metrics.mean_squared_error(holdout_pred,y_holdout))\n",
    "print(f\"Holdout score (RMSE): {score}\")    \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "129c28eb7371f81f3b772b69408a02d1e141a0d5c957c78df09fa0d1b2bc4f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
