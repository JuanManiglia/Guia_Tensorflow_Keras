{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modulo 5 : Regularización y Dropout**\n",
    "* Instructor: [Juan Maniglia](https://juanmaniglia.github.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 5.5: Benchmarking de Técnicas de Regularización\n",
    "\n",
    "Hasta ahora se han introducido bastantes hiperparámetros. Ajustar cada uno de estos valores puede tener un efecto en la puntuación obtenida por sus redes neuronales. Algunos de los hiperparámetros vistos hasta ahora incluyen:\n",
    "\n",
    "* Número de capas en la red neuronal\n",
    "* Cuantas neuronas hay en cada capa\n",
    "* Qué funciones de activación usar en cada capa\n",
    "* Porcentaje de abandono en cada capa\n",
    "* Valores L1 y L2 en cada capa\n",
    "\n",
    "Para probar cada uno de estos hiperparámetros, deberá ejecutar entrenar redes neuronales con múltiples configuraciones para cada hiperparámetro. Sin embargo, es posible que haya notado que las redes neuronales a menudo producen resultados algo diferentes cuando se entrenan varias veces. Esto se debe a que las redes neuronales comienzan con pesos aleatorios. Debido a esto, es necesario ajustar y evaluar los tiempos de una red neuronal para garantizar que un conjunto de hiperparámetros sea realmente mejor que otro. Bootstrapping puede ser un medio eficaz de evaluación comparativa (comparación) de dos conjuntos de hiperparámetros.\n",
    "\n",
    "Bootstrapping es similar a la validación cruzada. Ambos pasan por una serie de ciclos/pliegues que proporcionan conjuntos de validación y entrenamiento. Sin embargo, el arranque puede tener un número ilimitado de ciclos. Bootstrapping elige un nuevo tren y la validación divide cada ciclo, con reemplazo. El hecho de que cada ciclo se elija con reemplazo significa que, a diferencia de la validación cruzada, a menudo se seleccionarán filas repetidas entre ciclos. Si ejecuta el programa de arranque durante suficientes ciclos, habrá ciclos duplicados.\n",
    "\n",
    "En esta parte, utilizaremos bootstrapping para la evaluación comparativa de hiperparámetros. Entrenaremos una red neuronal para un número específico de divisiones (indicado por la constante SPLITS). Para estos ejemplos usamos 100. Compararemos el puntaje promedio al final de los 100. Al final de los ciclos, el puntaje promedio habrá convergido un poco. Esta puntuación final será una base de comparación mucho mejor que una única validación cruzada. Además, se rastreará el número promedio de épocas para dar una idea de un posible valor óptimo. Debido a que el conjunto de validación de detención temprana también se usa para evaluar la red neuronal, podría estar ligeramente inflado. Esto se debe a que nos detenemos y evaluamos en la misma muestra. Sin embargo, estamos usando las puntuaciones solo como medidas relativas para determinar la superioridad de un conjunto de hiperparámetros sobre otro, por lo que esta ligera inflación no debería presentar demasiado problema.\n",
    "\n",
    "Debido a que estamos evaluando comparativamente, mostraremos la cantidad de tiempo necesario para cada ciclo. La siguiente función se puede usar para formatear bien un lapso de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadena de tiempo bien formateada\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bootstrapping para regresión\n",
    "\n",
    "El bootstrapping de regresión usa el objeto **ShuffleSplit** para realizar las divisiones. Esto es similar a **KFold** para la validación cruzada, no se realiza el balanceo. Para demostrar esta técnica, intentaremos predecir la columna de edad para el conjunto de datos jh-simple. Estos datos se cargan con el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'product'\n",
    "df = pd.concat([df,pd.get_dummies(df['product'],prefix=\"product\")],axis=1)\n",
    "df.drop('product', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('age').drop('id')\n",
    "x = df[x_columns].values\n",
    "y = df['age'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código realiza el arranque. La arquitectura de la red neuronal se puede ajustar para comparar muchas configuraciones diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: score=0.598767, mean score=0.598767, stdev=0.000000, epochs=134, mean epochs=134,time=0:00:21.94\n",
      "#2: score=1.057863, mean score=0.828315, stdev=0.229548, epochs=104, mean epochs=119,time=0:00:15.15\n",
      "#3: score=0.666891, mean score=0.774507, stdev=0.202284, epochs=167, mean epochs=135,time=0:00:24.05\n",
      "#4: score=0.625468, mean score=0.737247, stdev=0.186692, epochs=99, mean epochs=126,time=0:00:14.51\n",
      "#5: score=0.608584, mean score=0.711515, stdev=0.174734, epochs=126, mean epochs=126,time=0:00:18.39\n",
      "#6: score=0.730423, mean score=0.714666, stdev=0.159665, epochs=93, mean epochs=120,time=0:00:13.64\n",
      "#7: score=0.517583, mean score=0.686511, stdev=0.163117, epochs=129, mean epochs=121,time=0:00:18.61\n",
      "#8: score=0.600120, mean score=0.675712, stdev=0.155234, epochs=132, mean epochs=123,time=0:00:19.15\n",
      "#9: score=0.733291, mean score=0.682110, stdev=0.147470, epochs=121, mean epochs=122,time=0:00:17.50\n",
      "#10: score=1.041067, mean score=0.718006, stdev=0.176548, epochs=102, mean epochs=120,time=0:00:14.91\n",
      "#11: score=1.030867, mean score=0.746448, stdev=0.190854, epochs=77, mean epochs=116,time=0:00:11.38\n",
      "#12: score=0.778674, mean score=0.749133, stdev=0.182945, epochs=119, mean epochs=116,time=0:00:17.31\n",
      "#13: score=0.635180, mean score=0.740367, stdev=0.178372, epochs=145, mean epochs=119,time=0:00:20.95\n",
      "#14: score=1.055083, mean score=0.762847, stdev=0.190035, epochs=96, mean epochs=117,time=0:00:15.13\n",
      "#15: score=0.499915, mean score=0.745318, stdev=0.194955, epochs=154, mean epochs=119,time=0:00:23.72\n",
      "#16: score=0.914223, mean score=0.755875, stdev=0.193141, epochs=107, mean epochs=119,time=0:00:15.65\n",
      "#17: score=0.612080, mean score=0.747416, stdev=0.190405, epochs=102, mean epochs=118,time=0:00:15.10\n",
      "#18: score=1.192057, mean score=0.772119, stdev=0.211218, epochs=89, mean epochs=116,time=0:00:13.05\n",
      "#19: score=0.684193, mean score=0.767491, stdev=0.206520, epochs=103, mean epochs=115,time=0:00:15.18\n",
      "#20: score=0.550609, mean score=0.756647, stdev=0.206766, epochs=180, mean epochs=118,time=0:00:26.52\n",
      "#21: score=0.715126, mean score=0.754670, stdev=0.201977, epochs=116, mean epochs=118,time=0:00:16.91\n",
      "#22: score=0.490825, mean score=0.742677, stdev=0.204844, epochs=117, mean epochs=118,time=0:00:16.91\n",
      "#23: score=0.520491, mean score=0.733017, stdev=0.205401, epochs=144, mean epochs=119,time=0:00:20.73\n",
      "#24: score=0.558237, mean score=0.725734, stdev=0.204087, epochs=132, mean epochs=120,time=0:00:19.13\n",
      "#25: score=0.661833, mean score=0.723178, stdev=0.200355, epochs=103, mean epochs=119,time=0:00:15.01\n",
      "#26: score=0.597927, mean score=0.718361, stdev=0.197935, epochs=113, mean epochs=119,time=0:00:16.37\n",
      "#27: score=0.570639, mean score=0.712889, stdev=0.196229, epochs=133, mean epochs=119,time=0:00:19.16\n",
      "#28: score=0.835421, mean score=0.717266, stdev=0.194030, epochs=80, mean epochs=118,time=0:00:11.73\n",
      "#29: score=0.666967, mean score=0.715531, stdev=0.190876, epochs=94, mean epochs=117,time=0:00:13.76\n",
      "#30: score=0.626294, mean score=0.712557, stdev=0.188350, epochs=94, mean epochs=116,time=0:00:13.68\n",
      "#31: score=0.562808, mean score=0.707726, stdev=0.187167, epochs=145, mean epochs=117,time=0:00:20.77\n",
      "#32: score=0.683882, mean score=0.706981, stdev=0.184266, epochs=80, mean epochs=116,time=0:00:11.74\n",
      "#33: score=0.834372, mean score=0.710841, stdev=0.182762, epochs=98, mean epochs=116,time=0:00:14.31\n",
      "#34: score=1.055731, mean score=0.720985, stdev=0.189248, epochs=96, mean epochs=115,time=0:00:14.11\n",
      "#35: score=0.680558, mean score=0.719830, stdev=0.186647, epochs=122, mean epochs=115,time=0:00:17.82\n",
      "#36: score=0.640121, mean score=0.717616, stdev=0.184502, epochs=135, mean epochs=116,time=0:00:20.05\n",
      "#37: score=1.036028, mean score=0.726222, stdev=0.189175, epochs=76, mean epochs=115,time=0:00:11.25\n",
      "#38: score=0.717295, mean score=0.725987, stdev=0.186674, epochs=121, mean epochs=115,time=0:00:17.47\n",
      "#39: score=0.630653, mean score=0.723542, stdev=0.184881, epochs=87, mean epochs=114,time=0:00:12.74\n",
      "#40: score=0.608893, mean score=0.720676, stdev=0.183430, epochs=103, mean epochs=114,time=0:00:15.11\n",
      "#41: score=1.227512, mean score=0.733038, stdev=0.197329, epochs=90, mean epochs=113,time=0:00:13.23\n",
      "#42: score=0.686717, mean score=0.731935, stdev=0.195093, epochs=101, mean epochs=113,time=0:00:14.70\n",
      "#43: score=0.653213, mean score=0.730104, stdev=0.193176, epochs=140, mean epochs=113,time=0:00:20.22\n",
      "#44: score=0.559162, mean score=0.726219, stdev=0.192660, epochs=142, mean epochs=114,time=0:00:20.53\n",
      "#45: score=1.014789, mean score=0.732632, stdev=0.195199, epochs=119, mean epochs=114,time=0:00:17.21\n",
      "#46: score=0.671121, mean score=0.731295, stdev=0.193273, epochs=81, mean epochs=113,time=0:00:11.89\n",
      "#47: score=0.599034, mean score=0.728481, stdev=0.192157, epochs=99, mean epochs=113,time=0:00:14.43\n",
      "#48: score=0.667713, mean score=0.727215, stdev=0.190342, epochs=92, mean epochs=113,time=0:00:13.43\n",
      "#49: score=0.867164, mean score=0.730071, stdev=0.189426, epochs=101, mean epochs=112,time=0:00:14.78\n",
      "#50: score=0.722274, mean score=0.729915, stdev=0.187526, epochs=91, mean epochs=112,time=0:00:13.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = ShuffleSplit(n_splits=SPLITS, test_size=0.1, random_state=42)\n",
    "\n",
    "# Sigue el progreso\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "num = 0\n",
    "\n",
    "# Bucle a través de muestras\n",
    "for train, test in boot.split(x):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Dividir en train/test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construir la red neural\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=5, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train en el bootstrap\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epochs_needed.append(epochs)\n",
    "    \n",
    "    # Predict en el arranque (validation)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # bootstrap's log loss\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    mean_benchmark.append(score)\n",
    "    m1 = statistics.mean(mean_benchmark)\n",
    "    m2 = statistics.mean(epochs_needed)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Grabar esta iteración\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)},time={hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrapping process for classification is similar and is presented in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping for Clasificación\n",
    "\n",
    "El arranque de regresión usa el objeto **StratifiedShuffleSplit** para realizar las divisiones. Esto es similar a **StratifiedKFold** para la validación cruzada, ya que las clases están equilibradas para que el muestreo no tenga efecto en las proporciones. Para demostrar esta técnica, intentaremos predecir la columna del producto para el conjunto de datos jh-simple. Estos datos se cargan con el siguiente código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Clasificación\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: score=0.660619, mean score=0.660619,stdev=0.000000, epochs=86, mean epochs=86, time=0:00:12.87\n",
      "#2: score=0.686717, mean score=0.673668,stdev=0.013049, epochs=65, mean epochs=75, time=0:00:09.78\n",
      "#3: score=0.679140, mean score=0.675492,stdev=0.010962, epochs=47, mean epochs=66, time=0:00:07.34\n",
      "#4: score=0.683686, mean score=0.677541,stdev=0.010135, epochs=72, mean epochs=67, time=0:00:10.80\n",
      "#5: score=0.679965, mean score=0.678025,stdev=0.009117, epochs=64, mean epochs=66, time=0:00:09.46\n",
      "#6: score=0.693619, mean score=0.680624,stdev=0.010150, epochs=53, mean epochs=64, time=0:00:07.85\n",
      "#7: score=0.709699, mean score=0.684778,stdev=0.013850, epochs=50, mean epochs=62, time=0:00:07.48\n",
      "#8: score=0.740468, mean score=0.691739,stdev=0.022518, epochs=43, mean epochs=60, time=0:00:06.59\n",
      "#9: score=0.617937, mean score=0.683539,stdev=0.031443, epochs=66, mean epochs=60, time=0:00:09.92\n",
      "#10: score=0.651650, mean score=0.680350,stdev=0.031326, epochs=88, mean epochs=63, time=0:00:13.06\n",
      "#11: score=0.704818, mean score=0.682574,stdev=0.030685, epochs=71, mean epochs=64, time=0:00:10.66\n",
      "#12: score=0.717403, mean score=0.685477,stdev=0.030916, epochs=67, mean epochs=64, time=0:00:10.20\n",
      "#13: score=0.702519, mean score=0.686788,stdev=0.030048, epochs=89, mean epochs=66, time=0:00:13.20\n",
      "#14: score=0.722521, mean score=0.689340,stdev=0.030382, epochs=50, mean epochs=65, time=0:00:07.78\n",
      "#15: score=0.658781, mean score=0.687303,stdev=0.030326, epochs=67, mean epochs=65, time=0:00:10.43\n",
      "#16: score=0.741016, mean score=0.690660,stdev=0.032113, epochs=41, mean epochs=63, time=0:00:06.38\n",
      "#17: score=0.630121, mean score=0.687099,stdev=0.034256, epochs=68, mean epochs=63, time=0:00:10.74\n",
      "#18: score=0.645738, mean score=0.684801,stdev=0.034613, epochs=77, mean epochs=64, time=0:00:12.07\n",
      "#19: score=0.599154, mean score=0.680293,stdev=0.038739, epochs=50, mean epochs=63, time=0:00:07.97\n",
      "#20: score=0.688458, mean score=0.680701,stdev=0.037800, epochs=75, mean epochs=64, time=0:00:11.51\n",
      "#21: score=0.626433, mean score=0.678117,stdev=0.038657, epochs=48, mean epochs=63, time=0:00:07.76\n",
      "#22: score=0.748031, mean score=0.681295,stdev=0.040479, epochs=51, mean epochs=63, time=0:00:08.13\n",
      "#23: score=0.578712, mean score=0.676835,stdev=0.044777, epochs=65, mean epochs=63, time=0:00:10.14\n",
      "#24: score=0.732394, mean score=0.679150,stdev=0.045218, epochs=43, mean epochs=62, time=0:00:06.83\n",
      "#25: score=0.586806, mean score=0.675456,stdev=0.047857, epochs=64, mean epochs=62, time=0:00:09.72\n",
      "#26: score=0.628356, mean score=0.673645,stdev=0.047794, epochs=88, mean epochs=63, time=0:00:13.57\n",
      "#27: score=0.733327, mean score=0.675855,stdev=0.048236, epochs=67, mean epochs=63, time=0:00:10.57\n",
      "#28: score=0.699733, mean score=0.676708,stdev=0.047574, epochs=94, mean epochs=64, time=0:00:14.66\n",
      "#29: score=0.658673, mean score=0.676086,stdev=0.046862, epochs=68, mean epochs=64, time=0:00:10.64\n",
      "#30: score=0.722163, mean score=0.677622,stdev=0.046811, epochs=57, mean epochs=64, time=0:00:09.14\n",
      "#31: score=0.704963, mean score=0.678504,stdev=0.046302, epochs=49, mean epochs=63, time=0:00:08.04\n",
      "#32: score=0.668249, mean score=0.678183,stdev=0.045608, epochs=67, mean epochs=64, time=0:00:10.53\n",
      "#33: score=0.606757, mean score=0.676019,stdev=0.046551, epochs=57, mean epochs=63, time=0:00:09.02\n",
      "#34: score=0.590464, mean score=0.673503,stdev=0.048085, epochs=88, mean epochs=64, time=0:00:13.37\n",
      "#35: score=0.498600, mean score=0.668505,stdev=0.055634, epochs=77, mean epochs=64, time=0:00:11.87\n",
      "#36: score=0.627663, mean score=0.667371,stdev=0.055265, epochs=106, mean epochs=66, time=0:00:16.22\n",
      "#37: score=0.674006, mean score=0.667550,stdev=0.054524, epochs=57, mean epochs=65, time=0:00:09.29\n",
      "#38: score=0.680185, mean score=0.667883,stdev=0.053840, epochs=63, mean epochs=65, time=0:00:09.84\n",
      "#39: score=0.752506, mean score=0.670053,stdev=0.054802, epochs=55, mean epochs=65, time=0:00:08.57\n",
      "#40: score=0.724212, mean score=0.671407,stdev=0.054770, epochs=43, mean epochs=64, time=0:00:06.86\n",
      "#41: score=0.744617, mean score=0.673192,stdev=0.055264, epochs=37, mean epochs=64, time=0:00:06.20\n",
      "#42: score=0.666928, mean score=0.673043,stdev=0.054610, epochs=51, mean epochs=63, time=0:00:08.01\n",
      "#43: score=0.689266, mean score=0.673420,stdev=0.054027, epochs=57, mean epochs=63, time=0:00:08.81\n",
      "#44: score=0.764013, mean score=0.675479,stdev=0.055090, epochs=56, mean epochs=63, time=0:00:08.68\n",
      "#45: score=0.648561, mean score=0.674881,stdev=0.054618, epochs=83, mean epochs=64, time=0:00:12.33\n",
      "#46: score=0.633820, mean score=0.673988,stdev=0.054352, epochs=45, mean epochs=63, time=0:00:06.94\n",
      "#47: score=0.672923, mean score=0.673966,stdev=0.053771, epochs=72, mean epochs=63, time=0:00:10.67\n",
      "#48: score=0.743728, mean score=0.675419,stdev=0.054133, epochs=51, mean epochs=63, time=0:00:07.80\n",
      "#49: score=0.696591, mean score=0.675851,stdev=0.053661, epochs=61, mean epochs=63, time=0:00:09.00\n",
      "#50: score=0.699002, mean score=0.676314,stdev=0.053221, epochs=56, mean epochs=63, time=0:00:08.43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "SPLITS = 50\n",
    "\n",
    "# Bootstrap\n",
    "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1, \n",
    "                                random_state=42)\n",
    "\n",
    "# Sigue el profreso\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "num = 0\n",
    "\n",
    "# Bucle a través de muestras\n",
    "for train, test in boot.split(x,df['product']):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Dividir train/test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construir la red neural\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=x.shape[1], activation='relu')) # Oculta 1\n",
    "    model.add(Dense(25, activation='relu')) # Oculta 2\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Salida\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=25, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train en el bootstrap\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "              callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epochs_needed.append(epochs)\n",
    "    \n",
    "    # Predict al arranque (validación)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # bootstrap's log loss\n",
    "    y_compare = np.argmax(y_test,axis=1) # para log loss\n",
    "    score = metrics.log_loss(y_compare, pred)\n",
    "    mean_benchmark.append(score)\n",
    "    m1 = statistics.mean(mean_benchmark)\n",
    "    m2 = statistics.mean(epochs_needed)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Grabar esta iteración\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f},\" +\\\n",
    "          f\"stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)},\" +\\\n",
    "          f\" time={hms_string(time_took)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking\n",
    "\n",
    "Ahora que hemos visto cómo arrancar tanto con la clasificación como con la regresión, podemos comenzar a intentar optimizar los hiperparámetros para los datos del conjunto de datos jh-simple. Para este ejemplo, codificaremos para la clasificación de la columna del producto. La evaluación será en pérdida de registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Leer el dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/jh-simple-dataset.csv\",\n",
    "    na_values=['NA','?'])\n",
    "\n",
    "# Generar dummies para 'job'\n",
    "df = pd.concat([df,pd.get_dummies(df['job'],prefix=\"job\")],axis=1)\n",
    "df.drop('job', axis=1, inplace=True)\n",
    "\n",
    "# Generar dummies para 'area'\n",
    "df = pd.concat([df,pd.get_dummies(df['area'],prefix=\"area\")],\n",
    "               axis=1)\n",
    "df.drop('area', axis=1, inplace=True)\n",
    "\n",
    "# Tratar Missing values en income\n",
    "med = df['income'].median()\n",
    "df['income'] = df['income'].fillna(med)\n",
    "\n",
    "# Standarizar rangos\n",
    "df['income'] = zscore(df['income'])\n",
    "df['aspect'] = zscore(df['aspect'])\n",
    "df['save_rate'] = zscore(df['save_rate'])\n",
    "df['age'] = zscore(df['age'])\n",
    "df['subscriptions'] = zscore(df['subscriptions'])\n",
    "\n",
    "# Convertir a numpy - Clasificación\n",
    "x_columns = df.columns.drop('product').drop('id')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df['product']) # Clasificación\n",
    "products = dummies.columns\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realicé algunas optimizaciones y el código está configurado actualmente con la mejor configuración que se me ocurrió. Más adelante en este curso veremos cómo podemos utilizar un proceso automático para optimizar los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1: score=0.591907, mean score=0.591907, stdev=0.000000, epochs=217, mean epochs=217, time=0:00:56.38\n",
      "#2: score=0.660223, mean score=0.626065, stdev=0.034158, epochs=190, mean epochs=203, time=0:00:49.85\n",
      "#3: score=0.696548, mean score=0.649559, stdev=0.043380, epochs=210, mean epochs=205, time=0:00:54.98\n",
      "#4: score=0.614519, mean score=0.640799, stdev=0.040517, epochs=198, mean epochs=203, time=0:00:51.70\n",
      "#5: score=0.603057, mean score=0.633251, stdev=0.039258, epochs=194, mean epochs=201, time=0:00:50.77\n",
      "#6: score=0.774661, mean score=0.656819, stdev=0.063731, epochs=162, mean epochs=195, time=0:00:42.68\n",
      "#7: score=0.624923, mean score=0.652263, stdev=0.060050, epochs=176, mean epochs=192, time=0:00:46.23\n",
      "#8: score=0.678533, mean score=0.655546, stdev=0.056840, epochs=213, mean epochs=195, time=0:00:54.34\n",
      "#9: score=0.630719, mean score=0.652788, stdev=0.054154, epochs=195, mean epochs=195, time=0:01:58.95\n",
      "#10: score=0.693280, mean score=0.656837, stdev=0.052792, epochs=156, mean epochs=191, time=0:01:47.54\n",
      "#11: score=0.661506, mean score=0.657262, stdev=0.050353, epochs=208, mean epochs=192, time=0:02:24.90\n",
      "#12: score=0.623821, mean score=0.654475, stdev=0.049087, epochs=188, mean epochs=192, time=0:02:12.03\n",
      "#13: score=0.617799, mean score=0.651654, stdev=0.048163, epochs=187, mean epochs=191, time=0:02:08.89\n",
      "#14: score=0.712096, mean score=0.655971, stdev=0.048952, epochs=166, mean epochs=190, time=0:01:57.87\n",
      "#15: score=0.627389, mean score=0.654065, stdev=0.047827, epochs=255, mean epochs=194, time=0:03:03.14\n",
      "#16: score=0.663942, mean score=0.654683, stdev=0.046370, epochs=249, mean epochs=197, time=0:02:56.13\n",
      "#17: score=0.748232, mean score=0.660186, stdev=0.050082, epochs=173, mean epochs=196, time=0:02:02.22\n",
      "#18: score=0.638260, mean score=0.658968, stdev=0.048929, epochs=176, mean epochs=195, time=0:02:03.46\n",
      "#19: score=0.719880, mean score=0.662173, stdev=0.049528, epochs=128, mean epochs=191, time=0:01:32.85\n",
      "#20: score=0.707211, mean score=0.664425, stdev=0.049262, epochs=168, mean epochs=190, time=0:01:57.92\n",
      "#21: score=0.708488, mean score=0.666524, stdev=0.048982, epochs=209, mean epochs=191, time=0:02:29.72\n",
      "#22: score=0.652667, mean score=0.665894, stdev=0.047943, epochs=194, mean epochs=191, time=0:02:13.93\n",
      "#23: score=0.623373, mean score=0.664045, stdev=0.047684, epochs=275, mean epochs=195, time=0:03:11.60\n",
      "#24: score=0.722521, mean score=0.666481, stdev=0.048120, epochs=141, mean epochs=192, time=0:01:41.67\n",
      "#25: score=0.697109, mean score=0.667707, stdev=0.047529, epochs=214, mean epochs=193, time=0:02:30.38\n",
      "#26: score=0.647856, mean score=0.666943, stdev=0.046762, epochs=178, mean epochs=193, time=0:00:50.43\n",
      "#27: score=0.765108, mean score=0.670579, stdev=0.049491, epochs=218, mean epochs=194, time=0:00:57.80\n",
      "#28: score=0.746661, mean score=0.673296, stdev=0.050609, epochs=230, mean epochs=195, time=0:01:00.32\n",
      "#29: score=0.608794, mean score=0.671072, stdev=0.051102, epochs=285, mean epochs=198, time=0:01:15.90\n",
      "#30: score=0.653162, mean score=0.670475, stdev=0.050346, epochs=177, mean epochs=197, time=0:00:47.84\n",
      "#31: score=0.585145, mean score=0.667722, stdev=0.051771, epochs=198, mean epochs=197, time=0:00:52.91\n",
      "#32: score=0.702284, mean score=0.668802, stdev=0.051309, epochs=125, mean epochs=195, time=0:00:34.25\n",
      "#33: score=0.662639, mean score=0.668616, stdev=0.050537, epochs=279, mean epochs=197, time=0:01:13.39\n",
      "#34: score=0.717196, mean score=0.670044, stdev=0.050460, epochs=163, mean epochs=196, time=0:00:45.07\n",
      "#35: score=0.696414, mean score=0.670798, stdev=0.049928, epochs=218, mean epochs=197, time=0:00:57.74\n",
      "#36: score=0.699361, mean score=0.671591, stdev=0.049453, epochs=199, mean epochs=197, time=0:00:58.03\n",
      "#37: score=0.703662, mean score=0.672458, stdev=0.049056, epochs=161, mean epochs=196, time=0:00:45.47\n",
      "#38: score=0.636033, mean score=0.671499, stdev=0.048757, epochs=272, mean epochs=198, time=0:01:14.49\n",
      "#39: score=0.569856, mean score=0.668893, stdev=0.050738, epochs=232, mean epochs=199, time=0:01:04.11\n",
      "#40: score=0.575564, mean score=0.666560, stdev=0.052176, epochs=240, mean epochs=200, time=0:01:06.30\n",
      "#41: score=0.638775, mean score=0.665882, stdev=0.051714, epochs=173, mean epochs=199, time=0:00:48.14\n",
      "#42: score=0.698012, mean score=0.666647, stdev=0.051329, epochs=138, mean epochs=198, time=0:00:38.02\n",
      "#43: score=0.683021, mean score=0.667028, stdev=0.050788, epochs=174, mean epochs=197, time=0:00:48.51\n",
      "#44: score=0.566308, mean score=0.664739, stdev=0.052404, epochs=252, mean epochs=198, time=0:01:08.94\n",
      "#45: score=0.636558, mean score=0.664113, stdev=0.051984, epochs=242, mean epochs=199, time=0:01:06.16\n",
      "#46: score=0.633744, mean score=0.663453, stdev=0.051606, epochs=289, mean epochs=201, time=0:01:18.57\n",
      "#47: score=0.695850, mean score=0.664142, stdev=0.051268, epochs=173, mean epochs=201, time=0:00:46.91\n",
      "#48: score=0.634272, mean score=0.663520, stdev=0.050910, epochs=168, mean epochs=200, time=0:00:45.80\n",
      "#49: score=0.590499, mean score=0.662029, stdev=0.051435, epochs=240, mean epochs=201, time=0:01:05.41\n",
      "#50: score=0.591079, mean score=0.660610, stdev=0.051878, epochs=204, mean epochs=201, time=0:00:55.65\n",
      "#51: score=0.708741, mean score=0.661554, stdev=0.051798, epochs=175, mean epochs=200, time=0:00:47.63\n",
      "#52: score=0.653626, mean score=0.661402, stdev=0.051310, epochs=154, mean epochs=199, time=0:00:42.04\n",
      "#53: score=0.591293, mean score=0.660079, stdev=0.051711, epochs=185, mean epochs=199, time=0:00:48.58\n",
      "#54: score=0.651437, mean score=0.659919, stdev=0.051243, epochs=188, mean epochs=199, time=0:00:51.83\n",
      "#55: score=0.643130, mean score=0.659613, stdev=0.050824, epochs=230, mean epochs=200, time=0:01:04.32\n",
      "#56: score=0.674875, mean score=0.659886, stdev=0.050409, epochs=177, mean epochs=199, time=0:00:46.85\n",
      "#57: score=0.663029, mean score=0.659941, stdev=0.049967, epochs=209, mean epochs=199, time=0:00:59.10\n",
      "#58: score=0.727800, mean score=0.661111, stdev=0.050315, epochs=150, mean epochs=198, time=0:00:43.89\n",
      "#59: score=0.703439, mean score=0.661829, stdev=0.050186, epochs=147, mean epochs=198, time=0:00:40.45\n",
      "#60: score=0.688753, mean score=0.662277, stdev=0.049885, epochs=133, mean epochs=196, time=0:00:35.75\n",
      "#61: score=0.651764, mean score=0.662105, stdev=0.049492, epochs=157, mean epochs=196, time=0:00:43.19\n",
      "#62: score=0.705556, mean score=0.662806, stdev=0.049396, epochs=246, mean epochs=197, time=0:01:08.57\n",
      "#63: score=0.713455, mean score=0.663610, stdev=0.049409, epochs=148, mean epochs=196, time=0:00:40.48\n",
      "#64: score=0.638918, mean score=0.663224, stdev=0.049117, epochs=154, mean epochs=195, time=0:00:43.20\n",
      "#65: score=0.619625, mean score=0.662553, stdev=0.049032, epochs=260, mean epochs=196, time=0:01:12.11\n",
      "#66: score=0.655027, mean score=0.662439, stdev=0.048668, epochs=139, mean epochs=195, time=0:00:39.14\n",
      "#67: score=0.551985, mean score=0.660791, stdev=0.050126, epochs=268, mean epochs=196, time=0:01:14.18\n",
      "#68: score=0.646517, mean score=0.660581, stdev=0.049786, epochs=176, mean epochs=196, time=0:00:49.70\n",
      "#69: score=0.718616, mean score=0.661422, stdev=0.049908, epochs=139, mean epochs=195, time=0:00:39.53\n",
      "#70: score=0.525620, mean score=0.659482, stdev=0.052105, epochs=222, mean epochs=196, time=0:01:01.30\n",
      "#71: score=0.690518, mean score=0.659919, stdev=0.051866, epochs=136, mean epochs=195, time=0:00:38.64\n",
      "#72: score=0.635414, mean score=0.659579, stdev=0.051584, epochs=169, mean epochs=194, time=0:00:46.78\n",
      "#73: score=0.675905, mean score=0.659802, stdev=0.051265, epochs=156, mean epochs=194, time=0:00:42.76\n",
      "#74: score=0.721468, mean score=0.660635, stdev=0.051413, epochs=143, mean epochs=193, time=0:00:38.79\n",
      "#75: score=0.651897, mean score=0.660519, stdev=0.051078, epochs=175, mean epochs=193, time=0:00:45.85\n",
      "#76: score=0.628566, mean score=0.660099, stdev=0.050872, epochs=248, mean epochs=194, time=0:01:07.99\n",
      "#77: score=0.596188, mean score=0.659269, stdev=0.051056, epochs=302, mean epochs=195, time=0:01:22.28\n",
      "#78: score=0.598528, mean score=0.658490, stdev=0.051186, epochs=200, mean epochs=195, time=0:00:54.76\n",
      "#79: score=0.639397, mean score=0.658248, stdev=0.050905, epochs=226, mean epochs=195, time=0:01:03.02\n",
      "#80: score=0.742720, mean score=0.659304, stdev=0.051449, epochs=176, mean epochs=195, time=0:00:50.42\n",
      "#81: score=0.724659, mean score=0.660111, stdev=0.051638, epochs=142, mean epochs=195, time=0:00:40.97\n",
      "#82: score=0.550749, mean score=0.658777, stdev=0.052707, epochs=337, mean epochs=196, time=0:01:35.00\n",
      "#83: score=0.672321, mean score=0.658940, stdev=0.052409, epochs=152, mean epochs=196, time=0:00:44.19\n",
      "#84: score=0.656785, mean score=0.658915, stdev=0.052097, epochs=184, mean epochs=196, time=0:00:52.44\n",
      "#85: score=0.670215, mean score=0.659048, stdev=0.051804, epochs=169, mean epochs=195, time=0:00:46.42\n",
      "#86: score=0.692093, mean score=0.659432, stdev=0.051623, epochs=210, mean epochs=195, time=0:00:58.66\n",
      "#87: score=0.651856, mean score=0.659345, stdev=0.051332, epochs=146, mean epochs=195, time=0:00:41.14\n",
      "#88: score=0.670213, mean score=0.659468, stdev=0.051053, epochs=154, mean epochs=194, time=0:00:42.58\n",
      "#89: score=0.635606, mean score=0.659200, stdev=0.050827, epochs=183, mean epochs=194, time=0:00:50.88\n",
      "#90: score=0.623585, mean score=0.658804, stdev=0.050682, epochs=227, mean epochs=195, time=0:01:04.22\n",
      "#91: score=0.601960, mean score=0.658180, stdev=0.050750, epochs=178, mean epochs=194, time=0:00:50.50\n",
      "#92: score=0.648830, mean score=0.658078, stdev=0.050482, epochs=227, mean epochs=195, time=0:01:02.99\n",
      "#93: score=0.689143, mean score=0.658412, stdev=0.050312, epochs=172, mean epochs=195, time=0:00:47.68\n",
      "#94: score=0.625722, mean score=0.658064, stdev=0.050156, epochs=199, mean epochs=195, time=0:00:55.87\n",
      "#95: score=0.647228, mean score=0.657950, stdev=0.049904, epochs=285, mean epochs=196, time=0:01:18.92\n",
      "#96: score=0.688205, mean score=0.658266, stdev=0.049738, epochs=216, mean epochs=196, time=0:01:01.07\n",
      "#97: score=0.661898, mean score=0.658303, stdev=0.049483, epochs=177, mean epochs=196, time=0:00:49.95\n",
      "#98: score=0.605867, mean score=0.657768, stdev=0.049511, epochs=247, mean epochs=196, time=0:01:10.04\n",
      "#99: score=0.637882, mean score=0.657567, stdev=0.049300, epochs=409, mean epochs=198, time=0:01:50.74\n",
      "#100: score=0.652439, mean score=0.657516, stdev=0.049056, epochs=250, mean epochs=199, time=0:01:07.69\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.keras.initializers\n",
    "import statistics\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
    "\n",
    "SPLITS = 100\n",
    "\n",
    "# Bootstrap\n",
    "boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
    "\n",
    "# Sigue el progreso\n",
    "mean_benchmark = []\n",
    "epochs_needed = []\n",
    "num = 0\n",
    "\n",
    "# Bucle a través de muestras\n",
    "for train, test in boot.split(x,df['product']):\n",
    "    start_time = time.time()\n",
    "    num+=1\n",
    "\n",
    "    # Dividir train/test\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "\n",
    "    # Construir la red neural\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=x.shape[1], activation=PReLU(), \\\n",
    "        kernel_regularizer=regularizers.l2(1e-4))) # Oculta 1\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation=PReLU(), \\\n",
    "        activity_regularizer=regularizers.l2(1e-4))) # Oculta 2\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation=PReLU(), \\\n",
    "        activity_regularizer=regularizers.l2(1e-4)\n",
    "    )) # Oculta 3\n",
    "#    model.add(Dropout(0.5)) - Por lo general, un mejor rendimiento\n",
    "# sin abandono en la capa final\n",
    "    model.add(Dense(y.shape[1],activation='softmax')) # Salida\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "    # Train en el bootstrap\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test), \\\n",
    "              callbacks=[monitor],verbose=0,epochs=1000)\n",
    "    epochs = monitor.stopped_epoch\n",
    "    epochs_needed.append(epochs)\n",
    "    \n",
    "    # Predict al arranque (validación)\n",
    "    pred = model.predict(x_test)\n",
    "  \n",
    "    # bootstrap's log loss\n",
    "    y_compare = np.argmax(y_test,axis=1) # para el cálculo de log loss\n",
    "    score = metrics.log_loss(y_compare, pred)\n",
    "    mean_benchmark.append(score)\n",
    "    m1 = statistics.mean(mean_benchmark)\n",
    "    m2 = statistics.mean(epochs_needed)\n",
    "    mdev = statistics.pstdev(mean_benchmark)\n",
    "    \n",
    "    # Guardar esta iteración\n",
    "    time_took = time.time() - start_time\n",
    "    print(f\"#{num}: score={score:.6f}, mean score={m1:.6f}, stdev={mdev:.6f}, epochs={epochs}, mean epochs={int(m2)}, time={hms_string(time_took)}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "129c28eb7371f81f3b772b69408a02d1e141a0d5c957c78df09fa0d1b2bc4f41"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
